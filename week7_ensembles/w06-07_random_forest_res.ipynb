{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семинар основан на <a href=\"https://habr.com/en/company/ods/blog/324402/\">материале</a> ODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import binom\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits as load\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/bootstrap.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Важно! **\n",
    "    - Бутстрепная выборка имеет такой же размер, что и исходная\n",
    "    - Генерация с повторениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAGGING(Bootstrap AGGregetING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$a_{Bagging}(x) = \\frac{1}{M}\\sum_{i=1}^M b_i(x)$$\n",
    "\n",
    "$b_i(x)$ - обучен на бутстреп-выборке $X^i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/bagging.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество классификации одним решающим деревом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.7641195020655038\n"
     ]
    }
   ],
   "source": [
    "d3 = DecisionTreeClassifier() # Обычное решающее дерево\n",
    "\n",
    "print(\"Decision tree:\", cross_val_score(d3, X, y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество бэггинга над решающими деревьями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging: 0.8641988222075007\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging:\", cross_val_score(BaggingClassifier(d3), X, y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Какой недостаток есть у деревьев?\n",
    "- Как bagging борется с этим недостатком?\n",
    "- Как можно улучшить качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь при построении каждого узла будем отбирать случайные max_features признаков и искать информативное разбиение только по одному из них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Bagging: 0.8848364802374699\n"
     ]
    }
   ],
   "source": [
    "f = X.shape[1]\n",
    "rnd_d3 = DecisionTreeClassifier(max_features=int(f ** 0.5)) # Решающее дерево с рандомизацией в сплитах\n",
    "\n",
    "print(\"Randomized Bagging:\", cross_val_score(BaggingClassifier(rnd_d3), X, y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Алгоритм построения случайного леса из $N$ деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого $n = 1..N$:\n",
    "\n",
    "Сгенерировать выборку $X_n$ с помощью бутстрэпа;\n",
    "Построить решающее дерево $b_n$ по выборке $X_n$:\n",
    "    1. по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки\n",
    "    2. дерево строится, пока в каждом листе не более $n_{min}$ объектов или пока не достигнем определенной высоты дерева\n",
    "    3. при каждом разбиении сначала выбирается $m$ случайных признаков из $n$ исходных, и оптимальное разделение выборки ищется только среди них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый классификатор:\n",
    "    $$ a(x) = \\dfrac{1}{N} \\sum_{i=1}^{N} b_i(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m$ советуют выбирать равным:\n",
    "- $\\sqrt{n}$ для классификации\n",
    "- $\\dfrac{n}{3}$ для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand made Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимо реализовать класс `RandomForest`** (для решения задачи классификации)\n",
    "\n",
    "**Спецификация:**\n",
    "- конструктор содержит следующие параметры: \n",
    "    - `num_trees` - количество деревьев в лесе;\n",
    "    - `max_depth` - максимальная глубина дерева (по умолчанию - `None`); \n",
    "    - `max_features` - количество признаков, принимаемое к рассмотрению при разбиении (аналогичный параметр есть в sklearn имплементации) (по умолчанию - `None`); \n",
    "    - `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', по умолчанию - 'gini'); \n",
    "    \n",
    "- класс имеет методы `fit` и `predict`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `RandomForest`, представляющий собой Random Forest, обученный по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap(X, y, size):\n",
    "    # Implement random sampling here\n",
    "    sample_X, sample_y = <ваш код>\n",
    "    return sample_X, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, num_trees, max_depth=None, max_features=None, criterion='gini'):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        Create trees here, using bootstrap.\n",
    "        '''\n",
    "        <ваш код>\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Predict the label here using your grown trees.\n",
    "        '''\n",
    "        y_pred = np.zeros(X_test.shape[0])\n",
    "        <ваш код>\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет ирисов на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим наш Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 10\n",
    "max_depth = 10\n",
    "max_features = 'sqrt'\n",
    "criterion = 'gini'\n",
    "\n",
    "clf = RandomForest(num_trees=num_trees, max_depth=max_depth, max_features=max_features, criterion=criterion)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10\n",
    "max_features = None\n",
    "criterion = 'gini'\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features, criterion=criterion)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Предложить способы оптимизации алгоритма случайного леса (например стэкинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Сравнить с классом ExtraTreesClassifier sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Отобразить признаки на гистограме по убыванияю важности (воспользоваться свойствами estimators_ и feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
